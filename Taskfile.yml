# https://taskfile.dev

version: '3'

tasks:
  default:
    cmds:
      - task: datendienst
      - task: lobid-download
      - task: lobid-filter
      - task: lobid-extract
      - task: wikidata
      - task: output
    
  datendienst:
    desc: Download von GND-IDs aus dem DLA Datendienst
    dir: data
    cmds:
      # - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:AK&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 > dla-gnd-ak.txt
      - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:KS&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 | sort | uniq > dla-gnd-ks.txt
      - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:PE&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 | sort | uniq > dla-gnd-pe.txt
    preconditions:
      - command -v curl

  lobid-download:
    desc: Bulk-Download der GND als JSON-Lines über lobid-gnd
    dir: data
    cmds:
      # - curl -A "DLA Marbach OPAC Enrichment" --silent --compressed 'https://lobid.org/gnd/search?q=type:Work&format=jsonl' | gzip > lobid-download-ak.jsonl.gz
      - curl -A "DLA Marbach OPAC Enrichment" --silent --compressed 'https://lobid.org/gnd/search?q=type:Person&format=jsonl' | gzip > lobid-download-pe.jsonl.gz
      - curl -A "DLA Marbach OPAC Enrichment" --silent --compressed 'https://lobid.org/gnd/search?q=type:CorporateBody&format=jsonl' | gzip > lobid-download-ks.jsonl.gz
    preconditions:
      - command -v curl
      - command -v gzip

  lobid-filter:
    desc: GND-Download reduzieren auf im DLA verwendete GND-IDs
    dir: data
    cmds:
      # - python3 ../lobid-filter.py lobid-download-ak.jsonl.gz dla-gnd-ak.txt | gzip > lobid-filtered-ak.jsonl.gz
      - python3 ../lobid-filter.py lobid-download-pe.jsonl.gz dla-gnd-pe.txt | gzip > lobid-filtered-pe.jsonl.gz
      - python3 ../lobid-filter.py lobid-download-ks.jsonl.gz dla-gnd-ks.txt | gzip > lobid-filtered-ks.jsonl.gz
    sources:
      - lobid-download-*.jsonl.gz
      - dla-gnd-*.txt
      - ../lobid-filter.py
    generates:
      - lobid-filtered-*.jsonl.gz
    preconditions:
      - command -v python3
      - command -v gzip

  lobid-extract:
    desc: Gewünschte Daten in einzelne Tabellen extrahieren
    dir: data
    cmds:
      - zcat lobid-filtered-ks.jsonl.gz | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("http://www.wikidata.org/entity/(.*)").captures[].string | [$id, .] | @tsv' > ks-gnd-wikidata.tsv
      - zcat lobid-filtered-pe.jsonl.gz | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("http://www.wikidata.org/entity/(.*)").captures[].string | [$id, .] | @tsv' > pe-gnd-wikidata.tsv
    sources:
      - lobid-filtered-*.jsonl.gz
    generates:
      - ./*.tsv

  wikidata:
    desc: (TODO) Mit den aus lobid-extract ermittelten Wikidata IDs den Wikidata Query Service abfragen
    dir: data
    cmds:
      - cut -f 2 ks-gnd-wikidata.tsv | sort | uniq > dla-wikidata-ks.txt
      - cut -f 2 pe-gnd-wikidata.tsv | sort | uniq > dla-wikidata-pe.txt
    sources:
      - ./*-gnd-wikidata.tsv
    generates:
      - dla-wikidata-*.txt
    preconditions:
      - command -v jq

  output:
    desc: Plausibilitätsprüfung und ggf. Kopie der Daten in das Verzeichnis output
    dir: data
    cmds:
      - |
        for f in *.tsv; do
          old="$(wc -l < ../output/${f} || echo 0)"
          new="$(wc -l < ${f})"
          if ((new+10 >= old));
          then
            echo "$f $((new-old))"
          else
            echo 1>&2 "Generierter Cache für ${f} scheint zu klein zu sein! Bitte manuell prüfen."
            echo 1>&2 "Differenz: $((new-old))"
            exit 2
          fi
        done
      - cp *.tsv ../output/
    sources:
      - ./*.tsv
    generates:
      - ../output/*.tsv
