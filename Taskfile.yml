# https://taskfile.dev

version: '3'

set: [errexit, pipefail]

tasks:
  default:
    cmds:
      - task: datendienst
      - task: lobid-download
      - task: lobid-filter
      - task: lobid-extract
      - task: wikidata
      - task: output
    
  datendienst:
    desc: Download von GND-IDs aus dem DLA Datendienst
    dir: data
    cmds:
      - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:AK&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 > gnd-ak.txt
      - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:KS&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 > gnd-ks.txt
      - curl --silent --compressed 'https://dataservice.dla-marbach.de/v1/records?q=gnd_id_mv:%2A%20AND%20source:PE&fields=gnd_id_mv&format=jsonl' | cut -d '"' -f 4 > gnd-pe.txt
    preconditions:
      - command -v curl

  lobid-download:
    desc: Bulk-Download der GND als JSON-Lines über lobid-gnd
    dir: data
    cmds:
      - curl -A "DLA Marbach OPAC Enrichment; mailto:dla@felixlohmeier.de" --silent --compressed 'https://lobid.org/gnd/search?q=type:Work&format=jsonl' | gzip > lobid-download-ak.jsonl.gz
      - curl -A "DLA Marbach OPAC Enrichment; mailto:dla@felixlohmeier.de" --silent --compressed 'https://lobid.org/gnd/search?q=type:CorporateBody&format=jsonl' | gzip > lobid-download-ks.jsonl.gz
      - curl -A "DLA Marbach OPAC Enrichment; mailto:dla@felixlohmeier.de" --silent --compressed 'https://lobid.org/gnd/search?q=type:Person&format=jsonl' | gzip > lobid-download-pe.jsonl.gz
    preconditions:
      - command -v curl
      - command -v gzip

  lobid-filter:
    desc: GND-Download reduzieren auf im DLA verwendete GND-IDs
    dir: data
    cmds:
      - python3 ../lobid-filter.py lobid-download-ak.jsonl.gz gnd-ak.txt | gzip > lobid-filtered-ak.jsonl.gz
      - python3 ../lobid-filter.py lobid-download-ks.jsonl.gz gnd-ks.txt | gzip > lobid-filtered-ks.jsonl.gz
      - python3 ../lobid-filter.py lobid-download-pe.jsonl.gz gnd-pe.txt | gzip > lobid-filtered-pe.jsonl.gz
    sources:
      - lobid-download-*.jsonl.gz
      - gnd-*.txt
      - ../lobid-filter.py
    generates:
      - lobid-filtered-*.jsonl.gz
    preconditions:
      - command -v python3
      - command -v gzip

  lobid-extract:
    desc: Gewünschte Daten aus lobid-filtered in einzelne Tabellen extrahieren
    dir: data
    cmds:
      - | # Wikidata (sameAs http://www.wikidata.org/entity/)
        for x in ak ks pe; do
          zcat < lobid-filtered-${x}.jsonl.gz \
          | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("http://www.wikidata.org/entity/(.*)").captures[].string | [$id, .] | @tsv' \
          | awk '!x[$0]++' \
          | sort --stable --key 1,1 \
          > lobid-wikidata-${x}.tsv
        done
      - | # Wikipedia (sameAs https://de.wikipedia.org/wiki/)
        for x in ak ks pe; do
          zcat < lobid-filtered-${x}.jsonl.gz \
          | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("https://de.wikipedia.org/wiki/(.*)").captures[].string | [$id, .] | @tsv' \
          | awk '!x[$0]++' \
          | sort --stable --key 1,1 \
          > lobid-wikipedia-${x}.tsv
        done
      - | # Filmportal (sameAs https://www.filmportal.de/)
        for x in pe; do
          zcat < lobid-filtered-${x}.jsonl.gz \
          | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("https://www.filmportal.de/(.*)").captures[].string | [$id, .] | @tsv' \
          | awk '!x[$0]++' \
          | sort --stable --key 1,1 \
          > lobid-filmportal-${x}.tsv
        done
      - | # Deutsche Biographie (sameAs https://www.deutsche-biographie.de/)
        for x in pe; do
          zcat < lobid-filtered-${x}.jsonl.gz \
          | jq -r 'try .gndIdentifier as $id | .sameAs[].id | match("https://www.deutsche-biographie.de/(.*)").captures[].string | [$id, .] | @tsv' \
          | awk '!x[$0]++' \
          | sort --stable --key 1,1 \
          > lobid-deutsche-biographie-${x}.tsv
        done
      - | # Commons (depiction https://commons.wikimedia.org/wiki/Special:FilePath/)
        for x in ak ks pe; do
          zcat < lobid-filtered-${x}.jsonl.gz \
          | jq -r 'try .gndIdentifier as $id | .depiction[].id | match("https://commons.wikimedia.org/wiki/Special:FilePath/(.*)").captures[].string | [$id, .] | @tsv' \
          | awk '!x[$0]++' \
          | sort --stable --key 1,1 \
          > lobid-commons-${x}.tsv
        done
    sources:
      - lobid-filtered-*.jsonl.gz
    generates:
      - lobid-*.tsv
    preconditions:
      - command -v jq

  wikidata:
    desc: Mit den aus lobid-extract ermittelten Wikidata IDs den Wikidata Query Service abfragen
    dir: data
    cmds:
      - cut -f 2 lobid-wikidata-ak.tsv | LC_ALL=POSIX sort -u > qid-ak.txt
      - cut -f 2 lobid-wikidata-ks.tsv | LC_ALL=POSIX sort -u > qid-ks.txt
      - cut -f 2 lobid-wikidata-pe.tsv | LC_ALL=POSIX sort -u > qid-pe.txt
      - python3 ../wikidata-extract.py qid-ak.txt ak P18,P856,P2639
      - cd ak; for f in *.tsv; do mv ${f} ../wikidata-${f%.tsv}-ak.tsv; done; cd ..; rm -r ak
      - python3 ../wikidata-extract.py qid-ks.txt ks P18,P856,P2639
      - cd ks; for f in *.tsv; do mv ${f} ../wikidata-${f%.tsv}-ks.tsv; done; cd ..; rm -r ks
      - python3 ../wikidata-extract.py qid-pe.txt pe P18,P856,P2639,P109
      - cd pe; for f in *.tsv; do mv ${f} ../wikidata-${f%.tsv}-pe.tsv; done; cd ..; rm -r pe
    sources:
      - lobid-wikidata-*.tsv
      - ../wikidata-extract.py
    generates:
      - qid-*.txt
      - wikidata-*.tsv
    preconditions:
      - command -v jq

  output:
    desc: Plausibilitätsprüfung und ggf. Kopie der Daten in das Verzeichnis output
    dir: data
    cmds:
      - |
        for f in *.tsv; do
          old="$(wc -l < ../output/${f} || echo 0)"
          new="$(wc -l < ${f})"
          if ((new+10 >= old));
          then
            echo "$f $((new-old))"
          else
            echo 1>&2 "Generierter Cache für ${f} scheint zu klein zu sein! Bitte manuell prüfen."
            echo 1>&2 "Differenz: $((new-old))"
            exit 2
          fi
        done
      - cp *.tsv ../output/
    sources:
      - ./*.tsv
    generates:
      - ../output/*.tsv
